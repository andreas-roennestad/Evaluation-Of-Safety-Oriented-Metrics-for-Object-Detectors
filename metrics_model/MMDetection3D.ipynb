{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0223e65a",
   "metadata": {},
   "source": [
    "## This notebook generates the result file from mmdetection3d applied on nuscenes\n",
    "It is a by-the-book approach to use models from the mmdetection3d model zoo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad0f6d",
   "metadata": {},
   "source": [
    "#### Note: nuscenes-dev (either the original version from nuscene website, or the modified version, provided by us) and mmdetection3d must be correctly installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6fcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "from nuscenes.eval.prediction.splits import *\n",
    "from nuscenes.eval.detection import *\n",
    "from nuscenes.eval.detection import *\n",
    "from nuscenes.eval.detection.configs import *\n",
    "\n",
    "import nuscenes.eval.detection.config as cnfig\n",
    "import nuscenes.eval.detection.evaluate as dcl\n",
    "    \n",
    "from nuscenes.prediction import *\n",
    "from nuscenes.map_expansion.map_api import *\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618338af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 49.472 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 17.6 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "DATAROOT = '/cluster/work/andronn/MasterThesis/MASTER/mmdetection3d/data/nuscenes'\n",
    "nuscenes = NuScenes('v1.0-trainval', dataroot=DATAROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d5deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ego_list=nuscenes.ego_pose\n",
    "#curr_scene = nuscenes.scene[0]\n",
    "#nuscenes.list_scenes()\n",
    "#dir(nuscenes)\n",
    "#len(nuscenes.sample)\n",
    "#s=nuscenes.sample[0]\n",
    "#s['data']['RADAR_FRONT']\n",
    "#curr_scene\n",
    "#nuscenes.sample[0]\n",
    "#sample_curr=next(item for item in nuscenes.sample if item[\"token\"] == '30e55a3ec6184d8cb1944b39ba19d622')\n",
    "#sample_curr.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118b035",
   "metadata": {},
   "source": [
    "#### Path of the detector and to store results\n",
    "Path to configure detector and where detector results are stored. To be configured differently for each detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737f93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PWD; the python command is launched from this path\n",
    "PWD='/cluster/work/andronn/MasterThesis/MASTER/mmdetection3d/'\n",
    "#here we store results\n",
    "OUTPUT='/cluster/work/andronn/MasterThesis/MASTER/mmdetection3d'\n",
    "#here we store results\n",
    "PATH='/cluster/work/andronn/MasterThesis/MASTER/mmdetection3d/pgd_results/img_bbox/'\n",
    "FILE_JSON='results_nusc.json'\n",
    "RESULT_PATH=PATH+FILE_JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f4625",
   "metadata": {},
   "source": [
    "This is simply the execution of algorithms from the mmdetection3d model zoo. Algorithms  operate on the nuscene data. So there is nothing surpising: \n",
    "\n",
    "### Available detectors\n",
    "\n",
    "#### 1 pointpillars with backbone FPN (Feature Pyramid Networks) -- LIDAR-only\n",
    "Results in: './pointpillars_nuscenes_results/pts_bbox/results_nusc-fpn.json' \n",
    "\n",
    "python tools/test.py configs/pointpillars/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20200620_230405-2fa62f3d.pth --format-only --options 'jsonfile_prefix=./pointpillars_nuscenes_results'\n",
    "\n",
    "mAP: 40%\n",
    "\n",
    "#### 2 pointpillars with backbone SECFPN -- LIDAR-only\n",
    "Results in: './pointpillars_nuscenes_results/pts_bbox/results_nusc-secfpn.json' \n",
    "\n",
    "python tools/test.py configs/pointpillars/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d_20200620_230725-0817d270.pth --format-only --options 'jsonfile_prefix=./pointpillars_nuscenes_results'\n",
    "\n",
    "mAP: 35.17%\n",
    "\n",
    "#### 3 RegNET-X (RegNET WITH RegNetX-1.6gF-FPN)\n",
    "Results in: './regnetX_nuscenes_results-secfpn/pts_bbox/results_nusc-secfpn.json'\n",
    "\n",
    "python tools/test.py configs/regnet/hv_pointpillars_regnet-1.6gf_fpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_regnet-1.6gf_fpn_sbn-all_4x8_2x_nus-3d_20200629_050311-dcd4e090.pth --format-only --options 'jsonfile_prefix=./regnetX_nuscenes_results-secfpn'\n",
    "\n",
    "mAP: 48.24%\n",
    "\n",
    "#### 4 RegNET-X (RegNET WITH RegNetX-400MF-FPN)\n",
    "Results in: './regnetX_nuscenes_results-secfpn/pts_bbox/results_nusc-400MF.json'\n",
    "\n",
    "python tools/test.py configs/regnet/hv_pointpillars_regnet-400mf_fpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_regnet-400mf_fpn_sbn-all_4x8_2x_nus-3d_20200620_230239-c694dce7.pth --format-only --options 'jsonfile_prefix=./regnetX_nuscenes_results-secfpn'\n",
    "\n",
    "mAP: 44.84\n",
    "\n",
    "#### 5 RegNET-X (RegNET WITH 400MF-SECFPN)\n",
    "Results in: './regnetX_nuscenes_results-secfpn/pts_bbox/results_nusc-400mfsecfpn.json'\n",
    "\n",
    "python tools/test.py configs/regnet/hv_pointpillars_regnet-400mf_secfpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_regnet-400mf_secfpn_sbn-all_4x8_2x_nus-3d_20200620_230334-53044f32.pth --format-only --options 'jsonfile_prefix=./regnetX_nuscenes_results-secfpn'\n",
    "\n",
    "mAP: 41.15%\n",
    "\n",
    "#### 6 SSN with backbone SECFPN\n",
    "Results in: './ssn_nuscenes_results/pts_bbox/results_nusc-secfpn.json'\n",
    "\n",
    "python tools/test.py configs/ssn/hv_ssn_secfpn_sbn-all_2x16_2x_nus-3d.py checkpoints/hv_ssn_secfpn_sbn-all_2x16_2x_nus-3d_20201023_193737-5fda3f00.pth --format-only --options 'jsonfile_prefix=./ssn_nuscenes_results'\n",
    "\n",
    "mAP: 41.56%\n",
    "\n",
    "#### 7 SSN with backbone REGNET \n",
    "Results in: './ssn_nuscenes_results/pts_bbox/results_nusc-regnet.json'\n",
    "\n",
    "python tools/test.py configs/ssn/hv_ssn_regnet-400mf_secfpn_sbn-all_2x16_2x_nus-3d.py checkpoints/hv_ssn_regnet-400mf_secfpn_sbn-all_2x16_2x_nus-3d_20201024_232447-7af3d8c8.pth --format-only --options 'jsonfile_prefix=./ssn_nuscenes_results'\n",
    "\n",
    "mAP:46.95%\n",
    "\n",
    "#### 8 FCOSD with backbone resnet 101 (finetuned) -- camera only\n",
    "Results in './fcos_results/img_bbox/results_nusc.json'\n",
    "\n",
    "python tools/test.py configs/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune.py checkpoints/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210427_091419-35aaaad0.pth --format-only --options 'jsonfile_prefix=./fcos_results'\n",
    "\n",
    "mAP: 32.1%\n",
    "\n",
    "#### 9 PGD with backbone resnet 101 (finetuned) -- camera only\n",
    "Results in './pgd_results/img_bbox/results_nusc.json'\n",
    "\n",
    "python tools/test.py configs/pgd/pgd_r101_caffe_fpn_gn-head_2x16_2x_nus-mono3d_finetune.py checkpoints/pgd_r101_caffe_fpn_gn-head_2x16_2x_nus-mono3d_finetune_20211114_162135-5ec7c1cd.pth --format-only --options 'jsonfile_prefix=./pgd_results'\n",
    "\n",
    "mAP: 35,8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d4dba",
   "metadata": {},
   "source": [
    "ACRONYMS (as naming in the following differs with respect to the paper)\n",
    "\n",
    "First column is the algorithm name (as close as possible to naming in mmdetection3d), second is the abbreviation we use in our paper\n",
    "\n",
    "- FCOSD-RESNET101              FCOS\n",
    "- pointpillars-secfpn          SEC\n",
    "- pointpillars-fpn             FPN\n",
    "- regnet-regnetX_400MF-FPN     REG400\n",
    "- ssn-SECFPN                   SSN\n",
    "- regnet-regnetX_400MF-SECFPN  REGSEC (REG400SEC)\n",
    "- ssn-REGNET                   SSNREG\n",
    "- regnet-regnetX_FPN           REG1.6\n",
    "- pgd                          PGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05c633",
   "metadata": {},
   "source": [
    "### Test the detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da74115",
   "metadata": {},
   "source": [
    "This is the official nuScenes detection evaluation code.\n",
    "Results are written to the provided output_dir.\n",
    "nuScenes uses the following detection metrics:\n",
    "    - Mean Average Precision (mAP): Uses center-distance as matching criterion; averaged over distance thresholds.\n",
    "    - True Positive (TP) metrics: Average of translation, velocity, scale, orientation and attribute errors.\n",
    "    - nuScenes Detection Score (NDS): The weighted sum of the above.\n",
    "Here is an overview of the functions in this method:\n",
    "    - init: Loads GT annotations and predictions stored in JSON format and filters the boxes.\n",
    "    - run: Performs evaluation and dumps the metric data to disk.\n",
    "    - render: Renders various plots and dumps to disk.\n",
    "We assume that:\n",
    "    - Every sample_token is given in the results, although there may be not predictions for that sample.\n",
    "    Please see https://www.nuscenes.org/object-detection for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9b5e5",
   "metadata": {},
   "source": [
    "DetectionEval:\n",
    "    :param nusc: A NuScenes object.\n",
    "        :param config: A DetectionConfig object.\n",
    "        :param result_path: Path of the nuScenes JSON result file.\n",
    "        :param eval_set: The dataset split to evaluate on, e.g. train, val or test.\n",
    "        :param output_dir: Folder to save plots and results to.\n",
    "        :param verbose: Whether to print to stdout.\n",
    "\n",
    "                def main(self,\n",
    "             plot_examples: int = 0,\n",
    "             render_curves: bool = True) -> Dict[str, Any]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e73298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confvalue=cnfig.config_factory(\"detection_cvpr_2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae11ae",
   "metadata": {},
   "source": [
    "{\n",
    "  \"class_range\": {\n",
    "    \"car\": 50,\n",
    "    \"truck\": 50,\n",
    "    \"bus\": 50,\n",
    "    \"trailer\": 50,\n",
    "    \"construction_vehicle\": 50,\n",
    "    \"pedestrian\": 40,\n",
    "    \"motorcycle\": 40,\n",
    "    \"bicycle\": 40,\n",
    "    \"traffic_cone\": 30,\n",
    "    \"barrier\": 30\n",
    "  },\n",
    "  \"dist_fcn\": \"center_distance\",\n",
    "  \"dist_ths\": [0.5, 1.0, 2.0, 4.0],\n",
    "  \"dist_th_tp\": 2.0,\n",
    "  \"min_recall\": 0.1,\n",
    "  \"min_precision\": 0.1,\n",
    "  \"max_boxes_per_sample\": 500,\n",
    "  \"mean_ap_weight\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f685e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of scene that compose the val set\n",
    "eval=val = \\\n",
    "    ['scene-0003', 'scene-0012', 'scene-0013', 'scene-0014', 'scene-0015', 'scene-0016', 'scene-0017', 'scene-0018',\n",
    "     'scene-0035', 'scene-0036', 'scene-0038', 'scene-0039', 'scene-0092', 'scene-0093', 'scene-0094', 'scene-0095',\n",
    "     'scene-0096', 'scene-0097', 'scene-0098', 'scene-0099', 'scene-0100', 'scene-0101', 'scene-0102', 'scene-0103',\n",
    "     'scene-0104', 'scene-0105', 'scene-0106', 'scene-0107', 'scene-0108', 'scene-0109', 'scene-0110', 'scene-0221',\n",
    "     'scene-0268', 'scene-0269', 'scene-0270', 'scene-0271', 'scene-0272', 'scene-0273', 'scene-0274', 'scene-0275',\n",
    "     'scene-0276', 'scene-0277', 'scene-0278', 'scene-0329', 'scene-0330', 'scene-0331', 'scene-0332', 'scene-0344',\n",
    "     'scene-0345', 'scene-0346', 'scene-0519', 'scene-0520', 'scene-0521', 'scene-0522', 'scene-0523', 'scene-0524',\n",
    "     'scene-0552', 'scene-0553', 'scene-0554', 'scene-0555', 'scene-0556', 'scene-0557', 'scene-0558', 'scene-0559',\n",
    "     'scene-0560', 'scene-0561', 'scene-0562', 'scene-0563', 'scene-0564', 'scene-0565', 'scene-0625', 'scene-0626',\n",
    "     'scene-0627', 'scene-0629', 'scene-0630', 'scene-0632', 'scene-0633', 'scene-0634', 'scene-0635', 'scene-0636',\n",
    "     'scene-0637', 'scene-0638', 'scene-0770', 'scene-0771', 'scene-0775', 'scene-0777', 'scene-0778', 'scene-0780',\n",
    "     'scene-0781', 'scene-0782', 'scene-0783', 'scene-0784', 'scene-0794', 'scene-0795', 'scene-0796', 'scene-0797',\n",
    "     'scene-0798', 'scene-0799', 'scene-0800', 'scene-0802', 'scene-0904', 'scene-0905', 'scene-0906', 'scene-0907',\n",
    "     'scene-0908', 'scene-0909', 'scene-0910', 'scene-0911', 'scene-0912', 'scene-0913', 'scene-0914', 'scene-0915',\n",
    "     'scene-0916', 'scene-0917', 'scene-0919', 'scene-0920', 'scene-0921', 'scene-0922', 'scene-0923', 'scene-0924',\n",
    "     'scene-0925', 'scene-0926', 'scene-0927', 'scene-0928', 'scene-0929', 'scene-0930', 'scene-0931', 'scene-0962',\n",
    "     'scene-0963', 'scene-0966', 'scene-0967', 'scene-0968', 'scene-0969', 'scene-0971', 'scene-0972', 'scene-1059',\n",
    "     'scene-1060', 'scene-1061', 'scene-1062', 'scene-1063', 'scene-1064', 'scene-1065', 'scene-1066', 'scene-1067',\n",
    "     'scene-1068', 'scene-1069', 'scene-1070', 'scene-1071', 'scene-1072', 'scene-1073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76eabb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24228ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing nuScenes detection evaluation\n",
      "Loaded results from /cluster/work/andronn/MasterThesis/MASTER/mmdetection3d/pgd_results/img_bbox/results_nusc.json. Found detections for 6019 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6019 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations for val split from nuScenes version: v1.0-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6019/6019 [00:13<00:00, 459.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 6019 samples.\n",
      "Filtering predictions\n",
      "=> Original number of boxes: 530978\n",
      "=> After distance based filtering: 530743\n",
      "=> After LIDAR and RADAR points based filtering: 530743\n",
      "=> After bike rack filtering: 530371\n",
      "Filtering ground truth annotations\n",
      "=> Original number of boxes: 187528\n",
      "=> After distance based filtering: 134565\n",
      "=> After LIDAR and RADAR points based filtering: 121871\n",
      "=> After bike rack filtering: 121861\n"
     ]
    }
   ],
   "source": [
    "#execute detection on val set\n",
    "dt=dcl.DetectionEval(nuscenes,confvalue, RESULT_PATH, 'val', OUTPUT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06fa1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(dt)\n",
    "# type(dt.gt_boxes) # nuscenes.eval.common.data_classes.EvalBoxes\n",
    "# len(dt.gt_boxes.boxes) # è 6019\n",
    "# type(dt.sample_tokens)\n",
    "# len(dt.sample_tokens) # è 6019\n",
    "# type(dt.sample_tokens[0]) # è str\n",
    "# dt.gt_boxes.boxes.values() --> dict_values([[{'sample_token': 'fd8420396768425eabec9bdddf7e64b6', 'translation': [242.87, 926.036, 0.898], 'size': [1.726, 4.257, 1.489], 'rotation': [0.787419398050721, 0.0, 0.0, -0.616417627565468], 'velocity': array([ 0.16021727, -0.69494243]), 'ego_translation': (-7.026109314307774, 8.483742683721516, 0.898), 'num_pts': 173, 'detection_name': 'car', 'detection_score': -1.0, 'attribute_name': 'vehicle.moving'}, {'sample_token': 'fd8420396768425eabec9bdddf7e64b6', 'translation': [244.281, 934.941, 1.099], 'size': [1.71, 4.248, 1.527], 'rotation': [0.7424261677818073, 0.0, 0.0, 0.6699278956670037], 'velocity': array([0., 0.]), 'ego_translation': (-5.615109314307773, 17.388742683721603, 1.099), 'num_pts': 35, 'detection_name': 'car', 'detection_score': -1.0, 'attribute_name': 'vehicle.parked'}, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cae29dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering sample token 5376e3a2874542d8b440faa899e52b97\n",
      "Rendering sample token 14f665de1fa34d0a9d12838a5b77d687\n",
      "Accumulating metric data...\n",
      "Calculating metrics...\n",
      "Rendering PR and TP curves\n",
      "Saving metrics to: /cluster/work/andronn/MasterThesis/MASTER/mmdetection3d\n",
      "mAP: 0.3584\n",
      "mATE: 0.6674\n",
      "mASE: 0.2643\n",
      "mAOE: 0.4346\n",
      "mAVE: 0.9600\n",
      "mAAE: 0.1766\n",
      "NDS: 0.4289\n",
      "Eval time: 180.0s\n",
      "\n",
      "Per-class results:\n",
      "Object Class\tAP\tATE\tASE\tAOE\tAVE\tAAE\n",
      "car\t0.538\t0.514\t0.150\t0.095\t1.332\t0.140\n",
      "truck\t0.278\t0.755\t0.212\t0.146\t1.120\t0.210\n",
      "bus\t0.372\t0.702\t0.191\t0.165\t1.973\t0.295\n",
      "trailer\t0.139\t1.019\t0.237\t0.660\t0.477\t0.223\n",
      "construction_vehicle\t0.060\t0.846\t0.409\t0.984\t0.099\t0.256\n",
      "pedestrian\t0.431\t0.651\t0.290\t0.594\t0.593\t0.167\n",
      "motorcycle\t0.354\t0.633\t0.263\t0.566\t1.456\t0.112\n",
      "bicycle\t0.335\t0.618\t0.295\t0.579\t0.630\t0.010\n",
      "traffic_cone\t0.581\t0.443\t0.314\tnan\tnan\tnan\n",
      "barrier\t0.495\t0.492\t0.282\t0.121\tnan\tnan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label_aps': defaultdict(<function nuscenes.eval.detection.data_classes.DetectionMetrics.__init__.<locals>.<lambda>()>,\n",
       "             {'car': defaultdict(float,\n",
       "                          {0.5: 0.17238441152622827,\n",
       "                           1.0: 0.4495187717391653,\n",
       "                           2.0: 0.7026284591770717,\n",
       "                           4.0: 0.8276765380551043}),\n",
       "              'truck': defaultdict(float,\n",
       "                          {0.5: 0.019446003955399506,\n",
       "                           1.0: 0.14714843901282196,\n",
       "                           2.0: 0.37997869043784227,\n",
       "                           4.0: 0.5664050916588804}),\n",
       "              'bus': defaultdict(float,\n",
       "                          {0.5: 0.028375015895221865,\n",
       "                           1.0: 0.23725596599480853,\n",
       "                           2.0: 0.5249402174030049,\n",
       "                           4.0: 0.6977897910464691}),\n",
       "              'trailer': defaultdict(float,\n",
       "                          {0.5: 0.0,\n",
       "                           1.0: 0.013024938556157682,\n",
       "                           2.0: 0.161713377734678,\n",
       "                           4.0: 0.3814678499782198}),\n",
       "              'construction_vehicle': defaultdict(float,\n",
       "                          {0.5: 0.0,\n",
       "                           1.0: 0.013991883476736326,\n",
       "                           2.0: 0.07205403127361432,\n",
       "                           4.0: 0.15356240437801275}),\n",
       "              'pedestrian': defaultdict(float,\n",
       "                          {0.5: 0.10607385459434948,\n",
       "                           1.0: 0.32951179107124456,\n",
       "                           2.0: 0.5683611115913922,\n",
       "                           4.0: 0.7210828281509916}),\n",
       "              'motorcycle': defaultdict(float,\n",
       "                          {0.5: 0.07667626480911338,\n",
       "                           1.0: 0.27702244458493497,\n",
       "                           2.0: 0.47635327914450953,\n",
       "                           4.0: 0.586999873248791}),\n",
       "              'bicycle': defaultdict(float,\n",
       "                          {0.5: 0.08566416762234391,\n",
       "                           1.0: 0.2583987733412062,\n",
       "                           2.0: 0.44527936754813896,\n",
       "                           4.0: 0.5523842636940914}),\n",
       "              'traffic_cone': defaultdict(float,\n",
       "                          {0.5: 0.30381226942305295,\n",
       "                           1.0: 0.5509505555053609,\n",
       "                           2.0: 0.6999572777360895,\n",
       "                           4.0: 0.7681619162284129}),\n",
       "              'barrier': defaultdict(float,\n",
       "                          {0.5: 0.2008947123653315,\n",
       "                           1.0: 0.4611371194458642,\n",
       "                           2.0: 0.6237770559088867,\n",
       "                           4.0: 0.6947391751851814})}),\n",
       " 'mean_dist_aps': {'car': 0.5380520451243924,\n",
       "  'truck': 0.278244556266236,\n",
       "  'bus': 0.3720902475848761,\n",
       "  'trailer': 0.13905154156726388,\n",
       "  'construction_vehicle': 0.05990207978209085,\n",
       "  'pedestrian': 0.43125739635199445,\n",
       "  'motorcycle': 0.3542629654468372,\n",
       "  'bicycle': 0.3354316430514451,\n",
       "  'traffic_cone': 0.580720504723229,\n",
       "  'barrier': 0.49513701572631597},\n",
       " 'mean_ap': 0.35841499956246803,\n",
       " 'label_tp_errors': defaultdict(<function nuscenes.eval.detection.data_classes.DetectionMetrics.__init__.<locals>.<lambda>()>,\n",
       "             {'car': defaultdict(float,\n",
       "                          {'trans_err': 0.5144250230676632,\n",
       "                           'scale_err': 0.14961647011340565,\n",
       "                           'orient_err': 0.0950813206564652,\n",
       "                           'vel_err': 1.3319352059934368,\n",
       "                           'attr_err': 0.13955368377276864}),\n",
       "              'truck': defaultdict(float,\n",
       "                          {'trans_err': 0.7551345288324531,\n",
       "                           'scale_err': 0.21157128826733312,\n",
       "                           'orient_err': 0.1463770547662483,\n",
       "                           'vel_err': 1.120126554924297,\n",
       "                           'attr_err': 0.2096733075273825}),\n",
       "              'bus': defaultdict(float,\n",
       "                          {'trans_err': 0.7022246619212154,\n",
       "                           'scale_err': 0.19056923320521058,\n",
       "                           'orient_err': 0.16489215264871246,\n",
       "                           'vel_err': 1.9726192406094605,\n",
       "                           'attr_err': 0.2950115837926064}),\n",
       "              'trailer': defaultdict(float,\n",
       "                          {'trans_err': 1.0188054400685895,\n",
       "                           'scale_err': 0.2371618214286504,\n",
       "                           'orient_err': 0.6603374745398908,\n",
       "                           'vel_err': 0.4768831300491523,\n",
       "                           'attr_err': 0.22327240846880958}),\n",
       "              'construction_vehicle': defaultdict(float,\n",
       "                          {'trans_err': 0.8460606299648014,\n",
       "                           'scale_err': 0.4092680925556409,\n",
       "                           'orient_err': 0.9839668230720051,\n",
       "                           'vel_err': 0.09940853776872056,\n",
       "                           'attr_err': 0.2559525171606231}),\n",
       "              'pedestrian': defaultdict(float,\n",
       "                          {'trans_err': 0.6513740138260086,\n",
       "                           'scale_err': 0.29028277160757193,\n",
       "                           'orient_err': 0.5944979229806076,\n",
       "                           'vel_err': 0.5933655542808578,\n",
       "                           'attr_err': 0.1672857694454426}),\n",
       "              'motorcycle': defaultdict(float,\n",
       "                          {'trans_err': 0.6327677690739529,\n",
       "                           'scale_err': 0.2632853999908682,\n",
       "                           'orient_err': 0.5655750708238308,\n",
       "                           'vel_err': 1.45559632235314,\n",
       "                           'attr_err': 0.11217177903508771}),\n",
       "              'bicycle': defaultdict(float,\n",
       "                          {'trans_err': 0.618256235957985,\n",
       "                           'scale_err': 0.2949955826617578,\n",
       "                           'orient_err': 0.5792607337797953,\n",
       "                           'vel_err': 0.6304196179064784,\n",
       "                           'attr_err': 0.010246426570307875}),\n",
       "              'traffic_cone': defaultdict(float,\n",
       "                          {'trans_err': 0.44276696943694044,\n",
       "                           'scale_err': 0.3143513372653502,\n",
       "                           'orient_err': nan,\n",
       "                           'vel_err': nan,\n",
       "                           'attr_err': nan}),\n",
       "              'barrier': defaultdict(float,\n",
       "                          {'trans_err': 0.49202191006803087,\n",
       "                           'scale_err': 0.2819040021117882,\n",
       "                           'orient_err': 0.12105417733899848,\n",
       "                           'vel_err': nan,\n",
       "                           'attr_err': nan})}),\n",
       " 'tp_errors': {'trans_err': 0.6673837182217641,\n",
       "  'scale_err': 0.26430059992075766,\n",
       "  'orient_err': 0.4345603034007282,\n",
       "  'vel_err': 0.960044270485693,\n",
       "  'attr_err': 0.17664593447162855},\n",
       " 'tp_scores': {'trans_err': 0.3326162817782359,\n",
       "  'scale_err': 0.7356994000792423,\n",
       "  'orient_err': 0.5654396965992718,\n",
       "  'vel_err': 0.03995572951430704,\n",
       "  'attr_err': 0.8233540655283714},\n",
       " 'nd_score': 0.42891401713117683,\n",
       " 'eval_time': 180.03668880462646,\n",
       " 'cfg': {'class_range': {'car': 50,\n",
       "   'truck': 50,\n",
       "   'bus': 50,\n",
       "   'trailer': 50,\n",
       "   'construction_vehicle': 50,\n",
       "   'pedestrian': 40,\n",
       "   'motorcycle': 40,\n",
       "   'bicycle': 40,\n",
       "   'traffic_cone': 30,\n",
       "   'barrier': 30},\n",
       "  'dist_fcn': 'center_distance',\n",
       "  'dist_ths': [0.5, 1.0, 2.0, 4.0],\n",
       "  'dist_th_tp': 2.0,\n",
       "  'min_recall': 0.1,\n",
       "  'min_precision': 0.1,\n",
       "  'max_boxes_per_sample': 500,\n",
       "  'mean_ap_weight': 5},\n",
       " 'meta': {'use_lidar': False,\n",
       "  'use_camera': True,\n",
       "  'use_radar': False,\n",
       "  'use_map': False,\n",
       "  'use_external': False}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.main(plot_examples=2,render_curves=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050168d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3eb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
